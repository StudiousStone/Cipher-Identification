{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vigenere', 'SS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading excel file containing training dataset\n",
    "xls = pd.ExcelFile('CryptoGrams.xlsx')\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting simple substitution and vignere substitution encyption training data in different dataframes\n",
    "ss = pd.read_excel(xls, \"SS\", header=None, names=[\"cipher\"])                    # simple substitution\n",
    "vig = pd.read_excel(xls, \"Vigenere\", header=None, names=[\"cipher\"])             # vignere substituion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this classification task, a cipher is considered as a bag of words (letters to be exact) and it is represented by a vector whose elements correspond to the frequency of occurrence of different characters in the cipher. The dimension of the vector is the same as the size of the dictionary built by including all the distinct words that occur in a corpus of ciphers. Let N be the size of the dictionary. Let ti be the ith word or term in the dictionary, and tf(ti,d) be the frequency of occurrence of ti in a given cipher d.\n",
    "\n",
    "A dictionary is constructed using a number of cipher texts in a corpus. We consider two methods for constructing the dictionary. In the first method, cipher texts generated using different encryption methods are included in a single corpus. This method is called the common dictionary method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the 2 dataframes to create a one large training set\n",
    "# This is created so that we can use common \"dictionary scheme\" \n",
    "df = pd.concat([ss, vig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training labels\n",
    "# 0 -> simple substitution\n",
    "# 1-> vignere substitution\n",
    "y =  [0]*50 + [1]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we find tfidf for every character in a cipher\n",
    "v = TfidfVectorizer(analyzer='char')      # Here we create a tfidf object to find the tfidf of a cipher with focus on every character rather than every word\n",
    "x = v.fit_transform(df['cipher'])         # we convert out text data into numbers that represent their tfidf representation\n",
    "len(v.get_feature_names())                # it gives us number of charcters in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code converts the test dataset into a test.csv file for further predicting tasks.\n",
    "import docx\n",
    "doc = docx.Document(\"dataset_cryptosystem.docx\")\n",
    "\n",
    "text = []\n",
    "for p in doc.paragraphs:\n",
    "    text.append(p.text)\n",
    "    \n",
    "len(text)\n",
    "\n",
    "d = [0,1,2,3,4,5,6,7,8,9,10,11, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 34, 35, 36, 38]\n",
    "d = sorted(d, reverse=True)\n",
    "for i in d:\n",
    "    del text[i]\n",
    "test = pd.DataFrame(text, columns=[\"cipher\"])\n",
    "#test.to_csv(\"test.csv\", index_label=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our test data\n",
    "#test = pd.read_csv(\"test.csv\", header=None, names=[\"cipher\"])\n",
    "# we convert our test data into its tfidf representation\n",
    "x_test = v.fit_transform(test['cipher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dimension of document vector is large, we consider the support vector machine based classifiers for identification of the encryption method for a cipher text. In the statistical methods for pattern classifications, as the dimension of input vector increases, number of parameters to estimate also increases. \n",
    "\n",
    "In SVM, Lagrangian coefficients are the parameters to be estimated. There will be one Lagrangian co-efficient with every example. Hence, the number of examples required to build the SVM is not dependent on the dimension of document vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  ['vignere', 'vignere', 'simple substitution', 'vignere', 'vignere', 'vignere', 'vignere', 'vignere', 'vignere', 'vignere', 'vignere', 'simple substitution', 'vignere', 'vignere', 'simple substitution', 'vignere', 'vignere', 'vignere', 'vignere', 'vignere']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjwal/anaconda3/envs/kaggle/lib/python3.5/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=45).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(max_iter=45)\n",
    "clf.fit(x, y)                         # fit our train data into our classifier\n",
    "clf_pred = clf.predict(x_test)                   # making prediction on test data\n",
    "pred = []\n",
    "for i in range(len(clf_pred)):\n",
    "    if clf_pred[i]==1:\n",
    "        pred.append(\"vignere\")\n",
    "    else:\n",
    "        pred.append(\"simple substitution\")\n",
    "print(\"Prediction : \", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
