{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vigenere', 'SS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading excel file containing training dataset\n",
    "xls = pd.ExcelFile('CryptoGrams.xlsx')\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting simple substitution and vignere substitution encyption training data in different dataframes\n",
    "ss = pd.read_excel(xls, \"SS\", header=None, names=[\"cipher\"])                    # simple substitution\n",
    "vig = pd.read_excel(xls, \"Vigenere\", header=None, names=[\"cipher\"])             # vignere substituion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this classification task, a cipher is considered as a bag of words (letters to be exact) and it is represented by a vector whose elements correspond to the frequency of occurrence of different characters in the cipher. The dimension of the vector is the same as the size of the dictionary built by including all the distinct words that occur in a corpus of ciphers. Let N be the size of the dictionary. Let ti be the ith word or term in the dictionary, and tf(ti,d) be the frequency of occurrence of ti in a given cipher d.\n",
    "\n",
    "A dictionary is constructed using a number of cipher texts in a corpus. We consider two methods for constructing the dictionary. In the first method, cipher texts generated using different encryption methods are included in a single corpus. This method is called the common dictionary method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the 2 dataframes to create a one large training set\n",
    "# This is created so that we can use common \"dictionary scheme\" \n",
    "df = pd.concat([ss, vig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training labels\n",
    "# 0 -> simple substitution\n",
    "# 1-> vignere substitution\n",
    "y =  [0]*50 + [1]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we find tfidf for every character in a cipher\n",
    "v = TfidfVectorizer(analyzer='char')      # Here we create a tfidf object to find the tfidf of a cipher with focus on every character rather than every word\n",
    "x = v.fit_transform(df['cipher'])         # we convert out text data into numbers that represent their tfidf representation\n",
    "len(v.get_feature_names())                # it gives us number of charcters in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape :  (100, 27)\n",
      "y shape :  (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# processing train data to feed into neural network\n",
    "import numpy as np\n",
    "x = x.todense()\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape((100,1))\n",
    "print(\"x shape : \", x.shape)\n",
    "print(\"y shape : \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code converts the test dataset into a test.csv file for further predicting tasks.\n",
    "import docx\n",
    "doc = docx.Document(\"dataset_cryptosystem.docx\")\n",
    "\n",
    "text = []\n",
    "for p in doc.paragraphs:\n",
    "    text.append(p.text)\n",
    "    \n",
    "len(text)\n",
    "\n",
    "d = [0,1,2,3,4,5,6,7,8,9,10,11, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 34, 35, 36, 38]\n",
    "d = sorted(d, reverse=True)\n",
    "for i in d:\n",
    "    del text[i]\n",
    "test = pd.DataFrame(text, columns=[\"cipher\"])\n",
    "# test.to_csv(\"test.csv\", index_label=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing test data\n",
    "#test = pd.read_csv(\"test.csv\", header=None, names=[\"cipher\"])\n",
    "\n",
    "x_test = v.fit_transform(test['cipher'])\n",
    "\n",
    "x_test = x_test.todense()\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s - loss: 0.6929 - acc: 0.4900\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s - loss: 0.6922 - acc: 0.4900\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s - loss: 0.6922 - acc: 0.5100\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s - loss: 0.6930 - acc: 0.5400\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s - loss: 0.6925 - acc: 0.5200\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s - loss: 0.6942 - acc: 0.4800\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s - loss: 0.6926 - acc: 0.5500\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s - loss: 0.6918 - acc: 0.5900\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s - loss: 0.6939 - acc: 0.5200\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s - loss: 0.6928 - acc: 0.4800\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s - loss: 0.6924 - acc: 0.4500\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s - loss: 0.6916 - acc: 0.5700\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s - loss: 0.6926 - acc: 0.5000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s - loss: 0.6930 - acc: 0.5100\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s - loss: 0.6928 - acc: 0.5600\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s - loss: 0.6923 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s - loss: 0.6935 - acc: 0.4700\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s - loss: 0.6917 - acc: 0.5500\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s - loss: 0.6930 - acc: 0.5200\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s - loss: 0.6928 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3fcee9b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network\n",
    "model = Sequential()                                          # sequential network\n",
    "model.add(Dense(64, input_dim=27, activation='relu'))         # adding 5 dense layer having 64 hidden units\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))                                        # dropout\n",
    "model.add(Dense(1, activation='sigmoid'))                      # output layer\n",
    "\n",
    "model.compile(loss='binary_crossentropy',                      # compiling the model with objective function-binary crossentropy, and optimizer-SGD\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y,                                                # fitting the model\n",
    "          epochs=20,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'simple substitution',\n",
       " 'simple substitution',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'vignere',\n",
       " 'simple substitution']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_test = model.predict(x_test)\n",
    "pred = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]>=0.5:\n",
    "        pred.append(\"vignere\")\n",
    "    else:\n",
    "        pred.append(\"simple substitution\")\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
